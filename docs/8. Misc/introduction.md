---
sidebar_position: 1
---

# Bias vs Variance in Machine Learning

---

## ğŸ“Œ **Bias**

### ğŸ” Definition

Bias refers to the **inability of a machine learning model to accurately capture the true relationship underlying the data**.

It measures how much the predicted values differ from the actual values.

---

### ğŸ”º High Bias

- The model **performs poorly on training data**.
- Indicates that the model is **not complex enough** to understand the patterns.
- Suggests the model is **underfitting**.
- ğŸ§  **Analogy**: A student who doesn't study enough and thus performs poorly even on familiar questions.
- ğŸ“ˆ **Visual**: A straight line trying to fit a curved dataset â€” shows large errors even in training.

---

### ğŸ”» Low Bias

- The model **performs well on training data**.
- It has **effectively captured the relationship** within the training set.

---

## ğŸ”„ **Variance**

### ğŸ” Definition

Variance refers to the **sensitivity of a machine learning model to small fluctuations in the training data**.

It measures how much the model's performance changes with different training sets.

---

### ğŸ”º High Variance

- The model **performs well on training data but poorly on test data**.
- Indicates the model has **memorized noise** â€” fails to generalise.
- Suggests the model is **overfitting**.
- ğŸ§  **Analogy**: A student who memorizes exact answers and fails when questions are reworded.
- ğŸ“ˆ **Visual**: A highly complex curve that fits every training point but performs badly on new data.

---

### ğŸ”» Low Variance

- The model has **consistent performance across datasets**.
- It is **not overly sensitive** to changes in training data.
- **Can generalise well** to unseen data.

---

## âš–ï¸ **Relationship to Overfitting and Underfitting**

### ğŸš« Underfitting

- The model **fails to capture patterns** in training data.
- Characterized by:
    - **High Bias**
    - **Low Variance**
- Performs poorly on both training and test data.

---

### âš ï¸ Overfitting

- The model **memorizes training data too closely**.
- Characterized by:
    - **Low Bias**
    - **High Variance**
- Performs well on training data but poorly on test data.

---

## âš–ï¸ **Bias-Variance Trade-off**

- A **core concept** in machine learning.
- Goal: Find a model with **both low bias and low variance**.
- Challenge:
    - Reducing bias â¬†ï¸ often increases variance â¬†ï¸
    - Reducing variance â¬‡ï¸ often increases bias â¬†ï¸
- ğŸ” This is the **bias-variance trade-off**.

---

### âœ… Ideal Scenario

- A model that strikes the **right balance**: moderate bias and variance.
- **Generalises well** without overfitting or underfitting.

---

### ğŸ§° Techniques to Handle the Trade-off

- **Regularisation**:
    - **L1 (Lasso)** and **L2 (Ridge)** regularisation.
    - These simplify the model to reduce variance while managing bias.
    - Help prevent **overfitting** by **penalizing complexity**.
- **Bagging**
- **Boosting**
